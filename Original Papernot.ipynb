{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This tutorial shows how to generate adversarial examples\n",
    "using FGSM in black-box setting.\n",
    "The original paper can be found at:\n",
    "https://arxiv.org/abs/1602.02697\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import flags\n",
    "\n",
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils import to_categorical\n",
    "from cleverhans.utils import set_log_level\n",
    "from cleverhans.utils_tf import model_train, model_eval, batch_eval\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.attacks_tf import jacobian_graph, jacobian_augmentation\n",
    "\n",
    "from cleverhans_tutorials.tutorial_models import make_basic_cnn, MLP\n",
    "from cleverhans_tutorials.tutorial_models import Flatten, Linear, ReLU, Softmax\n",
    "from cleverhans.utils import TemporaryLogLevel\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "def setup_tutorial():\n",
    "    \"\"\"\n",
    "    Helper function to check correct configuration of tf for tutorial\n",
    "    :return: True if setup checks completed\n",
    "    \"\"\"\n",
    "\n",
    "    # Set TF random seed to improve reproducibility\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def prep_bbox(sess, x, y, X_train, Y_train, X_test, Y_test,\n",
    "              nb_epochs, batch_size, learning_rate,\n",
    "              rng):\n",
    "    \"\"\"\n",
    "    Define and train a model that simulates the \"remote\"\n",
    "    black-box oracle described in the original paper.\n",
    "    :param sess: the TF session\n",
    "    :param x: the input placeholder for MNIST\n",
    "    :param y: the ouput placeholder for MNIST\n",
    "    :param X_train: the training data for the oracle\n",
    "    :param Y_train: the training labels for the oracle\n",
    "    :param X_test: the testing data for the oracle\n",
    "    :param Y_test: the testing labels for the oracle\n",
    "    :param nb_epochs: number of epochs to train model\n",
    "    :param batch_size: size of training batches\n",
    "    :param learning_rate: learning rate for training\n",
    "    :param rng: numpy.random.RandomState\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Define TF model graph (for the black-box model)\n",
    "    model = make_basic_cnn()\n",
    "    predictions = model(x)\n",
    "    print(\"Defined TensorFlow model graph.\")\n",
    "\n",
    "    # Train an MNIST model\n",
    "    train_params = {\n",
    "        'nb_epochs': nb_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate\n",
    "    }\n",
    "    model_train(sess, x, y, predictions, X_train, Y_train,\n",
    "                args=train_params, rng=rng)\n",
    "    # Print out the accuracy on legitimate data\n",
    "    eval_params = {'batch_size': batch_size}\n",
    "    accuracy = model_eval(sess, x, y, predictions, X_test, Y_test,\n",
    "                          args=eval_params)\n",
    "    print('Test accuracy of black-box on legitimate test '\n",
    "          'examples: ' + str(accuracy))\n",
    "\n",
    "    return model, predictions, accuracy\n",
    "\n",
    "\n",
    "def substitute_model(img_rows=28, img_cols=28, nb_classes=10):\n",
    "    \"\"\"\n",
    "    Defines the model architecture to be used by the substitute. Use\n",
    "    the example model interface.\n",
    "    :param img_rows: number of rows in input\n",
    "    :param img_cols: number of columns in input\n",
    "    :param nb_classes: number of classes in output\n",
    "    :return: tensorflow model\n",
    "    \"\"\"\n",
    "    input_shape = (None, img_rows, img_cols, 1)\n",
    "\n",
    "    # Define a fully connected model (it's different than the black-box)\n",
    "    layers = [Flatten(),\n",
    "              Linear(200),\n",
    "              ReLU(),\n",
    "              Linear(200),\n",
    "              ReLU(),\n",
    "              Linear(nb_classes),\n",
    "              Softmax()]\n",
    "\n",
    "    return MLP(layers, input_shape)\n",
    "\n",
    "\n",
    "def train_sub(sess, x, y, bbox_preds, X_sub, Y_sub, nb_classes,\n",
    "              nb_epochs_s, batch_size, learning_rate, data_aug, lmbda,\n",
    "              rng):\n",
    "    \"\"\"\n",
    "    This function creates the substitute by alternatively\n",
    "    augmenting the training data and training the substitute.\n",
    "    :param sess: TF session\n",
    "    :param x: input TF placeholder\n",
    "    :param y: output TF placeholder\n",
    "    :param bbox_preds: output of black-box model predictions\n",
    "    :param X_sub: initial substitute training data\n",
    "    :param Y_sub: initial substitute training labels\n",
    "    :param nb_classes: number of output classes\n",
    "    :param nb_epochs_s: number of epochs to train substitute model\n",
    "    :param batch_size: size of training batches\n",
    "    :param learning_rate: learning rate for training\n",
    "    :param data_aug: number of times substitute training data is augmented\n",
    "    :param lmbda: lambda from arxiv.org/abs/1602.02697\n",
    "    :param rng: numpy.random.RandomState instance\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Define TF model graph (for the black-box model)\n",
    "    model_sub = substitute_model()\n",
    "    preds_sub = model_sub(x)\n",
    "    print(\"Defined TensorFlow model graph for the substitute.\")\n",
    "\n",
    "    # Define the Jacobian symbolically using TensorFlow\n",
    "    grads = jacobian_graph(preds_sub, x, nb_classes)\n",
    "\n",
    "    # Train the substitute and augment dataset alternatively\n",
    "    for rho in xrange(data_aug):\n",
    "        print(\"Substitute training epoch #\" + str(rho))\n",
    "        train_params = {\n",
    "            'nb_epochs': nb_epochs_s,\n",
    "            'batch_size': batch_size,\n",
    "            'learning_rate': learning_rate\n",
    "        }\n",
    "        with TemporaryLogLevel(logging.WARNING, \"cleverhans.utils.tf\"):\n",
    "            model_train(sess, x, y, preds_sub, X_sub,\n",
    "                        to_categorical(Y_sub, nb_classes),\n",
    "                        init_all=False, args=train_params, rng=rng)\n",
    "\n",
    "        # If we are not at last substitute training iteration, augment dataset\n",
    "        if rho < data_aug - 1:\n",
    "            print(\"Augmenting substitute training data.\")\n",
    "            # Perform the Jacobian augmentation\n",
    "            lmbda_coef = 2 * int(int(rho / 3) != 0) - 1\n",
    "            X_sub = jacobian_augmentation(sess, x, X_sub, Y_sub, grads,\n",
    "                                          lmbda_coef * lmbda)\n",
    "\n",
    "            print(\"Labeling substitute training data.\")\n",
    "            # Label the newly generated synthetic points using the black-box\n",
    "            Y_sub = np.hstack([Y_sub, Y_sub])\n",
    "            X_sub_prev = X_sub[int(len(X_sub)/2):]\n",
    "            print('x sub', X_sub.shape)\n",
    "            print('x sub prev', X_sub_prev.shape)\n",
    "            print(azeuioghzefiyg)\n",
    "            eval_params = {'batch_size': batch_size}\n",
    "            bbox_val = batch_eval2(sess, [x], [bbox_preds], [X_sub_prev],\n",
    "                                  args=eval_params)[0]\n",
    "            # Note here that we take the argmax because the adversary\n",
    "            # only has access to the label (not the probabilities) output\n",
    "            # by the black-box model\n",
    "            Y_sub[int(len(X_sub)/2):] = np.argmax(bbox_val, axis=1)\n",
    "\n",
    "    return model_sub, preds_sub\n",
    "\n",
    "\n",
    "def mnist_blackbox(train_start=0, train_end=60000, test_start=0,\n",
    "                   test_end=10000, nb_classes=10, batch_size=128,\n",
    "                   learning_rate=0.001, nb_epochs=10, holdout=150, data_aug=6,\n",
    "                   nb_epochs_s=10, lmbda=0.1):\n",
    "    \"\"\"\n",
    "    MNIST tutorial for the black-box attack from arxiv.org/abs/1602.02697\n",
    "    :param train_start: index of first training set example\n",
    "    :param train_end: index of last training set example\n",
    "    :param test_start: index of first test set example\n",
    "    :param test_end: index of last test set example\n",
    "    :return: a dictionary with:\n",
    "             * black-box model accuracy on test set\n",
    "             * substitute model accuracy on test set\n",
    "             * black-box model accuracy on adversarial examples transferred\n",
    "               from the substitute model\n",
    "    \"\"\"\n",
    "\n",
    "    # Set logging level to see debug information\n",
    "    set_log_level(logging.DEBUG)\n",
    "\n",
    "    # Dictionary used to keep track and return key accuracies\n",
    "    accuracies = {}\n",
    "\n",
    "    # Perform tutorial setup\n",
    "    assert setup_tutorial()\n",
    "\n",
    "    # Create TF session\n",
    "    sess = tf.Session()\n",
    "\n",
    "    # Get MNIST data\n",
    "    X_train, Y_train, X_test, Y_test = data_mnist(train_start=train_start,\n",
    "                                                  train_end=train_end,\n",
    "                                                  test_start=test_start,\n",
    "                                                  test_end=test_end)\n",
    "\n",
    "    # Initialize substitute training set reserved for adversary\n",
    "    X_sub = X_test[:holdout]\n",
    "\n",
    "    Y_sub = np.argmax(Y_test[:holdout], axis=1) #colonne de classe !\n",
    "\n",
    "    # Redefine test set as remaining samples unavailable to adversaries\n",
    "    X_test = X_test[holdout:]\n",
    "    Y_test = Y_test[holdout:]\n",
    "\n",
    "    # Define input and output TF placeholders\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "    \n",
    "    # Seed random number generator so tutorial is reproducible\n",
    "    rng = np.random.RandomState([2017, 8, 30])\n",
    "\n",
    "    # Simulate the black-box model locally\n",
    "    # You could replace this by a remote labeling API for instance\n",
    "    print(\"Preparing the black-box model.\")\n",
    "    prep_bbox_out = prep_bbox(sess, x, y, X_train, Y_train, X_test, Y_test,\n",
    "                              nb_epochs, batch_size, learning_rate,\n",
    "                              rng=rng)\n",
    "    model, bbox_preds, accuracies['bbox'] = prep_bbox_out\n",
    "\n",
    "    # Train substitute using method from https://arxiv.org/abs/1602.02697\n",
    "    print(\"Training the substitute model.\")\n",
    "    train_sub_out = train_sub(sess, x, y, bbox_preds, X_sub, Y_sub,\n",
    "                              nb_classes, nb_epochs_s, batch_size,\n",
    "                              learning_rate, data_aug, lmbda, rng=rng)\n",
    "    model_sub, preds_sub = train_sub_out\n",
    "\n",
    "    # Evaluate the substitute model on clean test examples\n",
    "    eval_params = {'batch_size': batch_size}\n",
    "    acc = model_eval(sess, x, y, preds_sub, X_test, Y_test, args=eval_params)\n",
    "    accuracies['sub'] = acc\n",
    "    \n",
    "    #en bas: attack adverse\n",
    "    '''# Initialize the Fast Gradient Sign Method (FGSM) attack object.\n",
    "    fgsm_par = {'eps': 0.3, 'ord': np.inf, 'clip_min': 0., 'clip_max': 1.}\n",
    "    fgsm = FastGradientMethod(model_sub, sess=sess)\n",
    "\n",
    "    # Craft adversarial examples using the substitute\n",
    "    eval_params = {'batch_size': batch_size}\n",
    "    x_adv_sub = fgsm.generate(x, **fgsm_par)\n",
    "\n",
    "    # Evaluate the accuracy of the \"black-box\" model on adversarial examples\n",
    "    accuracy = model_eval(sess, x, y, model(x_adv_sub), X_test, Y_test,\n",
    "                          args=eval_params)\n",
    "    print('Test accuracy of oracle on adversarial examples generated '\n",
    "          'using the substitute: ' + str(accuracy))\n",
    "    accuracies['bbox_on_sub_adv_ex'] = accuracy'''\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "    mnist_blackbox(nb_classes=FLAGS.nb_classes,\n",
    "                   batch_size=FLAGS.batch_size,\n",
    "                   learning_rate=FLAGS.learning_rate,\n",
    "                   nb_epochs=1,#FLAGS.nb_epochs, \n",
    "                   holdout=FLAGS.holdout,\n",
    "                   data_aug=3,#FLAGS.data_aug, \n",
    "                   nb_epochs_s=1,#FLAGS.nb_epochs_s,\n",
    "                   lmbda=FLAGS.lmbda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAGS.holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the black-box model.\n",
      "Defined TensorFlow model graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-06-21 16:48:50,525 cleverhans] Epoch 0 took 30.207812547683716 seconds\n",
      "[INFO 2018-06-21 16:48:50,526 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of black-box on legitimate test examples: 0.982030456853\n",
      "Training the substitute model.\n",
      "Defined TensorFlow model graph for the substitute.\n",
      "Substitute training epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-06-21 16:49:00,513 cleverhans] Epoch 0 took 0.16910386085510254 seconds\n",
      "[INFO 2018-06-21 16:49:00,514 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "x sub (300, 28, 28, 1)\n",
      "x sub prev (150, 28, 28, 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'azeuioghzefiyg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-b84c82f28069>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m    275\u001b[0m                    \u001b[0mdata_aug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#FLAGS.data_aug,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                    \u001b[0mnb_epochs_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#FLAGS.nb_epochs_s,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                    lmbda=FLAGS.lmbda)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-b84c82f28069>\u001b[0m in \u001b[0;36mmnist_blackbox\u001b[0;34m(train_start, train_end, test_start, test_end, nb_classes, batch_size, learning_rate, nb_epochs, holdout, data_aug, nb_epochs_s, lmbda)\u001b[0m\n\u001b[1;32m    240\u001b[0m     train_sub_out = train_sub(sess, x, y, bbox_preds, X_sub, Y_sub,\n\u001b[1;32m    241\u001b[0m                               \u001b[0mnb_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                               learning_rate, data_aug, lmbda, rng=rng)\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0mmodel_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_sub_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-b84c82f28069>\u001b[0m in \u001b[0;36mtrain_sub\u001b[0;34m(sess, x, y, bbox_preds, X_sub, Y_sub, nb_classes, nb_epochs_s, batch_size, learning_rate, data_aug, lmbda, rng)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x sub'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x sub prev'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_sub_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mazeuioghzefiyg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0meval_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             bbox_val = batch_eval2(sess, [x], [bbox_preds], [X_sub_prev],\n",
      "\u001b[0;31mNameError\u001b[0m: name 'azeuioghzefiyg' is not defined"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def batch_eval2(sess, tf_inputs, tf_outputs, numpy_inputs, feed=None,\n",
    "               args=None):\n",
    "    \"\"\"\n",
    "    A helper function that computes a tensor on numpy inputs by batches.\n",
    "    :param sess:\n",
    "    :param tf_inputs:\n",
    "    :param tf_outputs:\n",
    "    :param numpy_inputs:\n",
    "    :param feed: An optional dictionary that is appended to the feeding\n",
    "             dictionary before the session runs. Can be used to feed\n",
    "             the learning phase of a Keras model for instance.\n",
    "    :param args: dict or argparse `Namespace` object.\n",
    "                 Should contain `batch_size`\n",
    "    \"\"\"\n",
    "    args = _ArgsWrapper(args or {})\n",
    "\n",
    "    assert args.batch_size, \"Batch size was not given in args dict\"\n",
    "\n",
    "    n = len(numpy_inputs)\n",
    "    assert n > 0\n",
    "    assert n == len(tf_inputs)\n",
    "    m = numpy_inputs[0].shape[0]\n",
    "    for i in xrange(1, n):\n",
    "        assert numpy_inputs[i].shape[0] == m\n",
    "    out = []\n",
    "    for _ in tf_outputs:\n",
    "        out.append([])\n",
    "    with sess.as_default():\n",
    "        for start in xrange(0, m, args.batch_size):\n",
    "            batch = start // args.batch_size\n",
    "            if batch % 100 == 0 and batch > 0:\n",
    "                _logger.debug(\"Batch \" + str(batch))\n",
    "\n",
    "            # Compute batch start and end indices\n",
    "            start = batch * args.batch_size\n",
    "            end = start + args.batch_size\n",
    "            numpy_input_batches = [numpy_input[start:end]\n",
    "                                   for numpy_input in numpy_inputs]\n",
    "            cur_batch_size = numpy_input_batches[0].shape[0]\n",
    "            assert cur_batch_size <= args.batch_size\n",
    "            for e in numpy_input_batches:\n",
    "                assert e.shape[0] == cur_batch_size\n",
    "\n",
    "            feed_dict = dict(zip(tf_inputs, numpy_input_batches))\n",
    "            if feed is not None:\n",
    "                feed_dict.update(feed)\n",
    "            numpy_output_batches = sess.run(tf_outputs, feed_dict=feed_dict)\n",
    "            for e in numpy_output_batches:\n",
    "                print(e)\n",
    "                print(e.shape)\n",
    "                print(cur_batch_size)\n",
    "                assert e.shape[0] == cur_batch_size, e.shape\n",
    "            for out_elem, numpy_output_batch in zip(out, numpy_output_batches):\n",
    "                out_elem.append(numpy_output_batch)\n",
    "\n",
    "    out = [np.concatenate(x, axis=0) for x in out]\n",
    "    for e in out:\n",
    "        assert e.shape[0] == m, e.shape\n",
    "    return out\n",
    "\n",
    "class _ArgsWrapper(object):\n",
    "\n",
    "    \"\"\"\n",
    "    Wrapper that allows attribute access to dictionaries\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args):\n",
    "        if not isinstance(args, dict):\n",
    "            args = vars(args)\n",
    "        self.args = args\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return self.args.get(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAGS.lmbda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
