{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas\n",
    "import numpy\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "\"\"\"\n",
    "This tutorial shows how to generate adversarial examples\n",
    "using FGSM in black-box setting.\n",
    "The original paper can be found at:\n",
    "https://arxiv.org/abs/1602.02697\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from six.moves import xrange\n",
    "\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import flags\n",
    "\n",
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils import to_categorical\n",
    "from cleverhans.utils import set_log_level\n",
    "from cleverhans.utils_tf import model_train, model_eval, batch_eval\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.attacks_tf import jacobian_graph, jacobian_augmentation\n",
    "\n",
    "from cleverhans_tutorials.tutorial_models import make_basic_cnn, MLP\n",
    "from cleverhans_tutorials.tutorial_models import Flatten, Linear, ReLU, Softmax\n",
    "from cleverhans.utils import TemporaryLogLevel\n",
    "\n",
    "from lad import lad_Thibault\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MOONS\n",
    "'''\n",
    "def get_moon():\n",
    "    X, y = make_moons(noise=0.3, random_state=1, n_samples=10000)\n",
    "    y2 = numpy.zeros((X.shape[0],2))\n",
    "    for k in range(len(y)):\n",
    "        y2[k][y[k]] = 1\n",
    "    return X, y2\n",
    "\n",
    "def get_german():\n",
    "    path_dataset='data/germancredit.csv'\n",
    "    X = pandas.read_csv(path_dataset, delimiter=\",\", index_col=0)\n",
    "    y = X.label\n",
    "    y = y - 1\n",
    "    X = X.iloc[:,X.columns != 'label']\n",
    "    X = (X-X.mean())/X.std()\n",
    "    y2 = numpy.zeros((X.shape[0],2)) #2=  nb de classes\n",
    "    for k in range(len(y)):\n",
    "        y2[k][y[k]] = 1\n",
    "    return numpy.array(X), numpy.array(y2)\n",
    "\n",
    "DATASETS_ = {'moons':get_moon,\n",
    "            'german': get_german}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a black-box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PAPERNOT BB\n",
    "'''\n",
    "def Papernot_bbox(sess, x, y, X_train, Y_train, X_test, Y_test,\n",
    "              nb_epochs, batch_size, learning_rate,\n",
    "              rng):\n",
    "    \"\"\"\n",
    "    Define and train a model that simulates the \"remote\"\n",
    "    black-box oracle described in the original paper.\n",
    "    :param sess: the TF session\n",
    "    :param x: the input placeholder for MNIST\n",
    "    :param y: the ouput placeholder for MNIST\n",
    "    :param X_train: the training data for the oracle\n",
    "    :param Y_train: the training labels for the oracle\n",
    "    :param X_test: the testing data for the oracle\n",
    "    :param Y_test: the testing labels for the oracle\n",
    "    :param nb_epochs: number of epochs to train model\n",
    "    :param batch_size: size of training batches\n",
    "    :param learning_rate: learning rate for training\n",
    "    :param rng: numpy.random.RandomState\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Define TF model graph (for the black-box model)\n",
    "    model = make_basic_cnn()\n",
    "    predictions = model(x)\n",
    "    print(\"Defined TensorFlow model graph.\")\n",
    "\n",
    "    # Train an MNIST model\n",
    "    train_params = {\n",
    "        'nb_epochs': nb_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate\n",
    "    }\n",
    "    model_train(sess, x, y, predictions, X_train, Y_train,\n",
    "                args=train_params, rng=rng)\n",
    "\n",
    "    # Print out the accuracy on legitimate data\n",
    "    eval_params = {'batch_size': batch_size}\n",
    "    accuracy = model_eval(sess, x, y, predictions, X_test, Y_test,\n",
    "                          args=eval_params)\n",
    "    print('Test accuracy of black-box on legitimate test '\n",
    "          'examples: ' + str(accuracy))\n",
    "\n",
    "    return model, predictions, accuracy\n",
    "\n",
    "def RF_bbox(X_train, Y_train, X_test, Y_test):\n",
    "    # Define RF model graph (for the black-box model)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, n_jobs=-1).fit(X_train, Y_train)\n",
    "    \n",
    "    # Print out the accuracy on legitimate data\n",
    "    #predictions = model.predict_proba(X_test)[1] TEST CHANGER PREDICTIONS > FONCTION\n",
    "    predictions=lambda x: model.predict_proba(x)[1] #predict_proba required ou alors changer du code (argmax et compagnie) de papernot\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, model.predict(X_test))\n",
    "    #roc_auc = roc_auc_score(Y_test, predictions[1][:,1])\n",
    "    print('Test accuracy of black-box on legitimate test '\n",
    "          'examples: ' + str(accuracy))\n",
    "    #print('Test ROC AUC of black-box on legitimate test ' 'examples: ' + str(roc_auc))\n",
    "        \n",
    "    \n",
    "    return model, predictions, accuracy\n",
    "    \n",
    "BB_MODELS_ = {'dnn': Papernot_bbox,\n",
    "            'rf': RF_bbox}\n",
    "#ne pas utiliser dnn ca marche pas pour le moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papernot Surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_tutorial():\n",
    "    \"\"\"\n",
    "    Helper function to check correct configuration of tf for tutorial\n",
    "    :return: True if setup checks completed\n",
    "    \"\"\"\n",
    "\n",
    "    # Set TF random seed to improve reproducibility\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    return True\n",
    "def substitute_model(img_rows=1, img_cols=2, nb_classes=2):\n",
    "    \"\"\"\n",
    "    Defines the model architecture to be used by the substitute. Use\n",
    "    the example model interface.\n",
    "    :param img_rows: number of rows in input\n",
    "    :param img_cols: number of columns in input\n",
    "    :param nb_classes: number of classes in output\n",
    "    :return: tensorflow model\n",
    "    \"\"\"\n",
    "    input_shape = (None, img_rows, img_cols, 1) #on garde format d'origine parce qu'on comprend pas grand chose mais on change valeurs\n",
    "\n",
    "    # Define a fully connected model (it's different than the black-box)\n",
    "    '''layers = [Flatten(),\n",
    "              Linear(200),\n",
    "              ReLU(),\n",
    "              Linear(200),\n",
    "              ReLU(),\n",
    "              Linear(nb_classes),\n",
    "              Softmax()]'''\n",
    "    layers = [Flatten(), Linear(nb_classes), Softmax()] #surrogate simplifié\n",
    "\n",
    "    return MLP(layers, input_shape)\n",
    "\n",
    "\n",
    "def train_sub(sess, x, y, bb_model, X_sub, Y_sub, nb_classes,\n",
    "              nb_epochs_s, batch_size, learning_rate, data_aug, lmbda,\n",
    "              rng):\n",
    "    \"\"\"\n",
    "    This function creates the substitute by alternatively\n",
    "    augmenting the training data and training the substitute.\n",
    "    :param sess: TF session\n",
    "    :param x: input TF placeholder\n",
    "    :param y: output TF placeholder\n",
    "    :param bbox_preds: output of black-box model predictions\n",
    "    :param X_sub: initial substitute training data\n",
    "    :param Y_sub: initial substitute training labels\n",
    "    :param nb_classes: number of output classes\n",
    "    :param nb_epochs_s: number of epochs to train substitute model\n",
    "    :param batch_size: size of training batches\n",
    "    :param learning_rate: learning rate for training\n",
    "    :param data_aug: number of times substitute training data is augmented\n",
    "    :param lmbda: lambda from arxiv.org/abs/1602.02697\n",
    "    :param rng: numpy.random.RandomState instance\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Define TF model graph (for the black-box model)\n",
    "    model_sub = substitute_model(img_cols=X_sub.shape[1])\n",
    "    preds_sub = model_sub(x)\n",
    "    print(\"Defined TensorFlow model graph for the substitute.\")\n",
    "\n",
    "    # Define the Jacobian symbolically using TensorFlow\n",
    "    grads = jacobian_graph(preds_sub, x, nb_classes)\n",
    "    # Train the substitute and augment dataset alternatively\n",
    "    for rho in xrange(data_aug):\n",
    "        print(\"Substitute training epoch #\" + str(rho))\n",
    "        train_params = {\n",
    "            'nb_epochs': nb_epochs_s,\n",
    "            'batch_size': batch_size,\n",
    "            'learning_rate': learning_rate\n",
    "        }\n",
    "        with TemporaryLogLevel(logging.WARNING, \"cleverhans.utils.tf\"):\n",
    "            model_train(sess, x, y, preds_sub, X_sub,\n",
    "                        to_categorical(Y_sub, nb_classes),\n",
    "                        init_all=False, args=train_params, rng=rng)\n",
    "\n",
    "        # If we are not at last substitute training iteration, augment dataset\n",
    "        if rho < data_aug - 1:\n",
    "            print(\"Augmenting substitute training data.\")\n",
    "            # Perform the Jacobian augmentation\n",
    "            lmbda_coef = 2 * int(int(rho / 3) != 0) - 1\n",
    "            X_sub = jacobian_augmentation(sess, x, X_sub, Y_sub, grads,\n",
    "                                          lmbda_coef * lmbda)\n",
    "            \n",
    "            print(\"Labeling substitute training data.\")\n",
    "            # Label the newly generated synthetic points using the black-box\n",
    "            Y_sub = numpy.hstack([Y_sub, Y_sub])\n",
    "            X_sub_prev = X_sub[int(len(X_sub)/2):] #on a double le dataset donc prev = ce qu'il y a de nouveau = la moitie\n",
    "            eval_params = {'batch_size': batch_size}\n",
    "            \n",
    "            #bbox_preds = tf.convert_to_tensor(bbox_preds, dtype=tf.float32) TEST CHANGER PREDICTIONS > FONCTION           \n",
    "            #bbox_val = batch_eval2(sess, [x], [bbox_preds], [X_sub_prev], args=eval_params)[0] TEST CHANGER PREDICTIONS > FONCTION\n",
    "            \n",
    "            #bbox_val = bbox_preds(X_sub_prev) #normalement batch eval sert juste à sortir les preds...?\n",
    "            bbox_val = bb_model.predict(X_sub_prev)\n",
    "            # Note here that we take the argmax because the adversary\n",
    "            # only has access to the label (not the probabilities) output\n",
    "            # by the black-box model\n",
    "            Y_sub[int(len(X_sub)/2):] = numpy.argmax(bbox_val, axis=1)\n",
    "    return model_sub, preds_sub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage: \n",
    "print(\"Training the substitute model.\")\n",
    "    train_sub_out = train_sub(sess, x, y, bbox_preds, X_sub, Y_sub,\n",
    "                              nb_classes, nb_epochs_s, batch_size,\n",
    "                              learning_rate, data_aug, lmbda, rng=rng)\n",
    "    model_sub, preds_sub = train_sub_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_points_hypersphere(x_center, radius_, n_points_):\n",
    "\n",
    "        res = []\n",
    "        while len(res) < n_points_:\n",
    "        \n",
    "            n_points_left_ = n_points_ - len(res)\n",
    "            # About half the points are lost in the test hypercube => hypersphere\n",
    "            lbound = numpy.repeat([x_center.values-(radius_/2.)], n_points_left_*2, axis=0)\n",
    "            hbound = numpy.repeat([x_center.values+(radius_/2.)], n_points_left_*2, axis=0)\n",
    "            points = numpy.random.uniform(low=lbound, high=hbound)\n",
    "            # Check if x_generated is within hypersphere (if kind=='hypersphere')\n",
    "            for x_generated in points:\n",
    "                if euclidean(x_generated, x_center.values) < radius_:\n",
    "                    res.append(x_generated)\n",
    "                if len(res) == n_points_:\n",
    "                    break\n",
    "\n",
    "        return pandas.DataFrame(numpy.array(res))\n",
    "    \n",
    "def generate_inside_ball(center, segment=(0,1), n=1): #verifier algo comprendre racine 1/d et rapport entre segment et radius\n",
    "    d = center.shape[0]\n",
    "    z = numpy.random.normal(0, 1, (n, d))\n",
    "    z = numpy.array([a * b / c for a, b, c in zip(z, numpy.random.uniform(*segment, n),  norm(z))])\n",
    "    z = z + center\n",
    "    return z \n",
    "def norm(v):\n",
    "        return numpy.linalg.norm(v, ord=2, axis=1) #array of l2 norms of vectors in v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training black box on 800 examples\n",
      "Testing black box and substitute on 190  examples\n",
      "Using  10  examples to start PP substitute\n",
      "Preparing the black-box model.\n",
      "Test accuracy of black-box on legitimate test examples: 0.7684210526315789\n",
      "Training the Pépèrenot substitute model.\n",
      "Defined TensorFlow model graph for the substitute.\n",
      "Substitute training epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-06-27 19:18:48,802 cleverhans] Epoch 0 took 0.09415221214294434 seconds\n",
      "[INFO 2018-06-27 19:18:48,803 cleverhans] Epoch 1 took 0.0005865097045898438 seconds\n",
      "[INFO 2018-06-27 19:18:48,804 cleverhans] Epoch 2 took 0.00041413307189941406 seconds\n",
      "[INFO 2018-06-27 19:18:48,805 cleverhans] Epoch 3 took 0.0004687309265136719 seconds\n",
      "[INFO 2018-06-27 19:18:48,806 cleverhans] Epoch 4 took 0.0003383159637451172 seconds\n",
      "[INFO 2018-06-27 19:18:48,806 cleverhans] Epoch 5 took 0.0003116130828857422 seconds\n",
      "[INFO 2018-06-27 19:18:48,807 cleverhans] Epoch 6 took 0.0003371238708496094 seconds\n",
      "[INFO 2018-06-27 19:18:48,808 cleverhans] Epoch 7 took 0.0003619194030761719 seconds\n",
      "[INFO 2018-06-27 19:18:48,808 cleverhans] Epoch 8 took 0.00037288665771484375 seconds\n",
      "[INFO 2018-06-27 19:18:48,809 cleverhans] Epoch 9 took 0.00038242340087890625 seconds\n",
      "[INFO 2018-06-27 19:18:48,810 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-06-27 19:19:02,962 cleverhans] Epoch 0 took 0.09948325157165527 seconds\n",
      "[INFO 2018-06-27 19:19:02,963 cleverhans] Epoch 1 took 0.0006444454193115234 seconds\n",
      "[INFO 2018-06-27 19:19:02,964 cleverhans] Epoch 2 took 0.0006618499755859375 seconds\n",
      "[INFO 2018-06-27 19:19:02,965 cleverhans] Epoch 3 took 0.0005359649658203125 seconds\n",
      "[INFO 2018-06-27 19:19:02,966 cleverhans] Epoch 4 took 0.0004322528839111328 seconds\n",
      "[INFO 2018-06-27 19:19:02,967 cleverhans] Epoch 5 took 0.0005624294281005859 seconds\n",
      "[INFO 2018-06-27 19:19:02,968 cleverhans] Epoch 6 took 0.0004477500915527344 seconds\n",
      "[INFO 2018-06-27 19:19:02,969 cleverhans] Epoch 7 took 0.00048160552978515625 seconds\n",
      "[INFO 2018-06-27 19:19:02,969 cleverhans] Epoch 8 took 0.0003561973571777344 seconds\n",
      "[INFO 2018-06-27 19:19:02,970 cleverhans] Epoch 9 took 0.0003666877746582031 seconds\n",
      "[INFO 2018-06-27 19:19:02,970 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-06-27 19:19:29,105 cleverhans] Epoch 0 took 0.11781716346740723 seconds\n",
      "[INFO 2018-06-27 19:19:29,107 cleverhans] Epoch 1 took 0.001051187515258789 seconds\n",
      "[INFO 2018-06-27 19:19:29,108 cleverhans] Epoch 2 took 0.0008361339569091797 seconds\n",
      "[INFO 2018-06-27 19:19:29,110 cleverhans] Epoch 3 took 0.0008704662322998047 seconds\n",
      "[INFO 2018-06-27 19:19:29,111 cleverhans] Epoch 4 took 0.0007464885711669922 seconds\n",
      "[INFO 2018-06-27 19:19:29,112 cleverhans] Epoch 5 took 0.0008094310760498047 seconds\n",
      "[INFO 2018-06-27 19:19:29,114 cleverhans] Epoch 6 took 0.000736236572265625 seconds\n",
      "[INFO 2018-06-27 19:19:29,115 cleverhans] Epoch 7 took 0.0009937286376953125 seconds\n",
      "[INFO 2018-06-27 19:19:29,116 cleverhans] Epoch 8 took 0.0006339550018310547 seconds\n",
      "[INFO 2018-06-27 19:19:29,117 cleverhans] Epoch 9 took 0.0006041526794433594 seconds\n",
      "[INFO 2018-06-27 19:19:29,117 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-06-27 19:20:20,537 cleverhans] Epoch 0 took 0.10551643371582031 seconds\n",
      "[INFO 2018-06-27 19:20:20,539 cleverhans] Epoch 1 took 0.0016813278198242188 seconds\n",
      "[INFO 2018-06-27 19:20:20,541 cleverhans] Epoch 2 took 0.0012249946594238281 seconds\n",
      "[INFO 2018-06-27 19:20:20,543 cleverhans] Epoch 3 took 0.0014140605926513672 seconds\n",
      "[INFO 2018-06-27 19:20:20,545 cleverhans] Epoch 4 took 0.0013492107391357422 seconds\n",
      "[INFO 2018-06-27 19:20:20,546 cleverhans] Epoch 5 took 0.0013561248779296875 seconds\n",
      "[INFO 2018-06-27 19:20:20,548 cleverhans] Epoch 6 took 0.0011968612670898438 seconds\n",
      "[INFO 2018-06-27 19:20:20,549 cleverhans] Epoch 7 took 0.0012660026550292969 seconds\n",
      "[INFO 2018-06-27 19:20:20,551 cleverhans] Epoch 8 took 0.001201629638671875 seconds\n",
      "[INFO 2018-06-27 19:20:20,553 cleverhans] Epoch 9 took 0.0015869140625 seconds\n",
      "[INFO 2018-06-27 19:20:20,553 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-06-27 19:22:05,639 cleverhans] Epoch 0 took 0.11149215698242188 seconds\n",
      "[INFO 2018-06-27 19:22:05,643 cleverhans] Epoch 1 took 0.002958536148071289 seconds\n",
      "[INFO 2018-06-27 19:22:05,646 cleverhans] Epoch 2 took 0.0030336380004882812 seconds\n",
      "[INFO 2018-06-27 19:22:05,650 cleverhans] Epoch 3 took 0.002886533737182617 seconds\n",
      "[INFO 2018-06-27 19:22:05,654 cleverhans] Epoch 4 took 0.0033159255981445312 seconds\n",
      "[INFO 2018-06-27 19:22:05,656 cleverhans] Epoch 5 took 0.002352476119995117 seconds\n",
      "[INFO 2018-06-27 19:22:05,659 cleverhans] Epoch 6 took 0.0022497177124023438 seconds\n",
      "[INFO 2018-06-27 19:22:05,662 cleverhans] Epoch 7 took 0.0026400089263916016 seconds\n",
      "[INFO 2018-06-27 19:22:05,665 cleverhans] Epoch 8 took 0.002621889114379883 seconds\n",
      "[INFO 2018-06-27 19:22:05,668 cleverhans] Epoch 9 took 0.002526998519897461 seconds\n",
      "[INFO 2018-06-27 19:22:05,668 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-06-27 19:25:44,387 cleverhans] Epoch 0 took 0.11306524276733398 seconds\n",
      "[INFO 2018-06-27 19:25:44,394 cleverhans] Epoch 1 took 0.005726814270019531 seconds\n",
      "[INFO 2018-06-27 19:25:44,400 cleverhans] Epoch 2 took 0.005811214447021484 seconds\n",
      "[INFO 2018-06-27 19:25:44,408 cleverhans] Epoch 3 took 0.0069124698638916016 seconds\n",
      "[INFO 2018-06-27 19:25:44,414 cleverhans] Epoch 4 took 0.005264759063720703 seconds\n",
      "[INFO 2018-06-27 19:25:44,419 cleverhans] Epoch 5 took 0.004702329635620117 seconds\n",
      "[INFO 2018-06-27 19:25:44,424 cleverhans] Epoch 6 took 0.005049228668212891 seconds\n",
      "[INFO 2018-06-27 19:25:44,430 cleverhans] Epoch 7 took 0.0050466060638427734 seconds\n",
      "[INFO 2018-06-27 19:25:44,435 cleverhans] Epoch 8 took 0.004989147186279297 seconds\n",
      "[INFO 2018-06-27 19:25:44,440 cleverhans] Epoch 9 took 0.004487514495849609 seconds\n",
      "[INFO 2018-06-27 19:25:44,441 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of oracle on adversarial examples generated using the substitute: 0.7052631578947368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'papernot': 0.379},\n",
       " {'bbox': 0.7684210526315789,\n",
       "  'bbox_on_sub_adv_ex': 0.7052631578947368,\n",
       "  'papernot': 0.6})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def main_fidelity(radius):\n",
    "    accuracies = {}\n",
    "    fidelities = {}\n",
    "    \n",
    "    \n",
    "    # Seed random number generator so tutorial is reproducible\n",
    "    rng = numpy.random.RandomState([2017, 8, 30])\n",
    "\n",
    "    # Thibault: Tensorflow stuff\n",
    "    set_log_level(logging.DEBUG)\n",
    "    assert setup_tutorial()\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Data\n",
    "    X, Y = DATASETS_['german']()\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20)\n",
    "    X_sub = X_test[:holdout]\n",
    "    Y_sub = numpy.argmax(Y_test[:holdout], axis=1)\n",
    "\n",
    "    ## Redefine test set as remaining samples unavailable to adversaries\n",
    "    ### N.B Thibault: c'est pour le substitute de Papernot\n",
    "    X_test = X_test[holdout:]\n",
    "    Y_test = Y_test[holdout:]\n",
    "    print(\"Training black box on\",X_train.shape[0], \"examples\")\n",
    "    print('Testing black box and substitute on', X_test.shape[0],' examples')\n",
    "    print(\"Using \", holdout, \" examples to start PP substitute\")\n",
    "    ## Define input and output TF placeholders\n",
    "    ### N.B. Thibault: restes de Tensorflow, utilisé pour le substitute de Papernot...\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 20))\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 2))  \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Instance to explain\n",
    "    x_toexplain = pandas.Series(X_test[0]).copy()\n",
    "    support_x_ = numpy.array(get_random_points_hypersphere(x_toexplain, radius_=radius, n_points_=1000))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Simulate the black-box model\n",
    "    print(\"Preparing the black-box model.\")\n",
    "    prep_bbox_out = BB_MODELS_['rf'](X_train, Y_train, X_test, Y_test)\n",
    "    bb_model, bbox_preds, accuracies['bbox'] = prep_bbox_out #bbox_preds fonction predict\n",
    "    \n",
    "    # Train PAPERNOT substitute\n",
    "    print(\"Training the Pépèrenot substitute model.\")\n",
    "    train_sub_pap = train_sub(sess, x, y, bb_model, X_sub, Y_sub,\n",
    "                              nb_classes, nb_epochs_s, batch_size,\n",
    "                              learning_rate, data_aug, lmbda, rng=rng)\n",
    "    model_sub, preds_sub = train_sub_pap\n",
    "    \n",
    "    #feed_dict = {x:support_x_, y:bbox_preds(support_x_)}\n",
    "    \n",
    "    eval_params = {'batch_size': batch_size}\n",
    "    pap_acc = model_eval(sess, x, y, preds_sub, X_test, Y_test, args=eval_params) \n",
    "    pap_fid = model_eval(sess, x, y, preds_sub, support_x_, bb_model.predict(support_x_) , args=eval_params)\n",
    "    accuracies['papernot'] = pap_acc\n",
    "    fidelities['papernot'] = pap_fid\n",
    "    \n",
    "    \n",
    "    # Train OUR subtitute\n",
    "    '''print(\"Training Local Surrogate substitute model.\")\n",
    "    pred = bb_model.predict\n",
    "    bb_model.predict = lambda x: pred(x)[:,1]\n",
    "    _, train_sub_ls = lad.LocalSurrogate(pandas.DataFrame(X), blackbox=bb_model, n_support_points=100, max_depth=3).get_local_surrogate(x_toexplain)\n",
    "    #ls_acc = accuracy_score(train_sub_ls.predict(X_test), Y_test)\n",
    "    ls_fid = accuracy_score(train_sub_ls.predict(support_x_), bb_model.predict(support_x_))\n",
    "    #accuracies['localsurrogate'] = ls_acc\n",
    "    fidelities['localsurrogate'] = ls_fid\n",
    "    '''\n",
    "\n",
    "    \n",
    "    # Initialize the Fast Gradient Sign Method (FGSM) attack object.\n",
    "    fgsm_par = {'eps': 0.5, 'ord': numpy.inf, 'clip_min': 0., 'clip_max': 1.} #ord: norme L1, l2 ou linfini\n",
    "    fgsm = FastGradientMethod(model_sub, sess=sess)\n",
    "\n",
    "    # Craft adversarial examples using the substitute\n",
    "    eval_params = {'batch_size': batch_size}\n",
    "    x_adv_sub = fgsm.generate(x, **fgsm_par)\n",
    "\n",
    "    # Evaluate the accuracy of the \"black-box\" model on adversarial examples\n",
    "    accuracy = accuracy_score(Y_test, bb_model.predict(sess.run(x_adv_sub, feed_dict={x: X_test})))\n",
    "    #model_eval(sess, x, y, bb_model.predict(x_adv_sub), X_test, Y_test,\n",
    "    #                      args=eval_params)\n",
    "    print('Test accuracy of oracle on adversarial examples generated '\n",
    "          'using the substitute: ' + str(accuracy))\n",
    "    accuracies['bbox_on_sub_adv_ex'] = accuracy\n",
    "    \n",
    "    return fidelities, accuracies\n",
    "\n",
    "\n",
    "\n",
    "nb_classes=2 #\n",
    "batch_size=20 #\n",
    "learning_rate=0.001 #\n",
    "nb_epochs=0 # Nombre d'itération bbox osef\n",
    "holdout=10 # Nombre d'exemples utilisés au début pour générer data (Pap-substitute)\n",
    "data_aug=6 # Nombre d'itérations d'augmentation du dataset {IMPORTANT pour Pap-substitute}\n",
    "nb_epochs_s=10 # Nombre d'itérations pour train substitute\n",
    "lmbda=0.1 # params exploration pour augmentation data\n",
    "radius_ = 0.5 # NEW\n",
    "main_fidelity(radius_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Il faut trouver une facon de faire la boucle\n",
    "\n",
    "pour radius:\n",
    "    genere black box\n",
    "    genere surrogate papernot\n",
    "    \n",
    "    pour observation dans test:\n",
    "        genere local surrogate\n",
    "        evalue papernot local\n",
    "        evalue local surrogate local\n",
    "outputs:\n",
    "papernot: {radius: [accuracy locale de chaque point}\n",
    "pareil pour ls}\n",
    "\n",
    "\n",
    "TODO: check histoire de boucle radius comment ca se goupille\n",
    "voir si ca tourne\n",
    "faire graphe...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training black box on 800 examples\n",
      "Testing black box and substitute on 150  examples\n",
      "Using  50  examples to start PP substitute\n",
      "Preparing the black-box model.\n",
      "Test accuracy of black-box on legitimate test examples: 0.7933333333333333\n",
      "Training the Pépèrenot substitute model.\n",
      "Defined TensorFlow model graph for the substitute.\n",
      "Substitute training epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-06-27 15:27:02,174 cleverhans] Epoch 0 took 0.03695559501647949 seconds\n",
      "[INFO 2018-06-27 15:27:02,176 cleverhans] Epoch 1 took 0.0011332035064697266 seconds\n",
      "[INFO 2018-06-27 15:27:02,177 cleverhans] Epoch 2 took 0.000989675521850586 seconds\n",
      "[INFO 2018-06-27 15:27:02,179 cleverhans] Epoch 3 took 0.0013225078582763672 seconds\n",
      "[INFO 2018-06-27 15:27:02,181 cleverhans] Epoch 4 took 0.0011136531829833984 seconds\n",
      "[INFO 2018-06-27 15:27:02,182 cleverhans] Epoch 5 took 0.001153707504272461 seconds\n",
      "[INFO 2018-06-27 15:27:02,183 cleverhans] Epoch 6 took 0.0009675025939941406 seconds\n",
      "[INFO 2018-06-27 15:27:02,185 cleverhans] Epoch 7 took 0.0009479522705078125 seconds\n",
      "[INFO 2018-06-27 15:27:02,186 cleverhans] Epoch 8 took 0.0010585784912109375 seconds\n",
      "[INFO 2018-06-27 15:27:02,187 cleverhans] Epoch 9 took 0.0010216236114501953 seconds\n",
      "[INFO 2018-06-27 15:27:02,188 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-06-27 15:27:06,947 cleverhans] Epoch 0 took 0.033199310302734375 seconds\n",
      "[INFO 2018-06-27 15:27:06,950 cleverhans] Epoch 1 took 0.001959562301635742 seconds\n",
      "[INFO 2018-06-27 15:27:06,953 cleverhans] Epoch 2 took 0.0021190643310546875 seconds\n",
      "[INFO 2018-06-27 15:27:06,955 cleverhans] Epoch 3 took 0.00176239013671875 seconds\n",
      "[INFO 2018-06-27 15:27:06,957 cleverhans] Epoch 4 took 0.0016868114471435547 seconds\n",
      "[INFO 2018-06-27 15:27:06,959 cleverhans] Epoch 5 took 0.0018417835235595703 seconds\n",
      "[INFO 2018-06-27 15:27:06,961 cleverhans] Epoch 6 took 0.0018846988677978516 seconds\n",
      "[INFO 2018-06-27 15:27:06,964 cleverhans] Epoch 7 took 0.002386331558227539 seconds\n",
      "[INFO 2018-06-27 15:27:06,966 cleverhans] Epoch 8 took 0.0018665790557861328 seconds\n",
      "[INFO 2018-06-27 15:27:06,969 cleverhans] Epoch 9 took 0.0019054412841796875 seconds\n",
      "[INFO 2018-06-27 15:27:06,969 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-06-27 15:27:17,211 cleverhans] Epoch 0 took 0.03695535659790039 seconds\n",
      "[INFO 2018-06-27 15:27:17,214 cleverhans] Epoch 1 took 0.003141164779663086 seconds\n",
      "[INFO 2018-06-27 15:27:17,218 cleverhans] Epoch 2 took 0.0033500194549560547 seconds\n",
      "[INFO 2018-06-27 15:27:17,222 cleverhans] Epoch 3 took 0.0036220550537109375 seconds\n",
      "[INFO 2018-06-27 15:27:17,225 cleverhans] Epoch 4 took 0.0028874874114990234 seconds\n",
      "[INFO 2018-06-27 15:27:17,229 cleverhans] Epoch 5 took 0.003096342086791992 seconds\n",
      "[INFO 2018-06-27 15:27:17,232 cleverhans] Epoch 6 took 0.002938985824584961 seconds\n",
      "[INFO 2018-06-27 15:27:17,236 cleverhans] Epoch 7 took 0.003136157989501953 seconds\n",
      "[INFO 2018-06-27 15:27:17,239 cleverhans] Epoch 8 took 0.0031452178955078125 seconds\n",
      "[INFO 2018-06-27 15:27:17,244 cleverhans] Epoch 9 took 0.004333972930908203 seconds\n",
      "[INFO 2018-06-27 15:27:17,245 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-06-27 15:27:39,082 cleverhans] Epoch 0 took 0.04013848304748535 seconds\n",
      "[INFO 2018-06-27 15:27:39,088 cleverhans] Epoch 1 took 0.006196022033691406 seconds\n",
      "[INFO 2018-06-27 15:27:39,096 cleverhans] Epoch 2 took 0.007002592086791992 seconds\n",
      "[INFO 2018-06-27 15:27:39,103 cleverhans] Epoch 3 took 0.006662130355834961 seconds\n",
      "[INFO 2018-06-27 15:27:39,111 cleverhans] Epoch 4 took 0.0069828033447265625 seconds\n",
      "[INFO 2018-06-27 15:27:39,118 cleverhans] Epoch 5 took 0.006784677505493164 seconds\n",
      "[INFO 2018-06-27 15:27:39,125 cleverhans] Epoch 6 took 0.006224632263183594 seconds\n",
      "[INFO 2018-06-27 15:27:39,132 cleverhans] Epoch 7 took 0.006426572799682617 seconds\n",
      "[INFO 2018-06-27 15:27:39,139 cleverhans] Epoch 8 took 0.006488323211669922 seconds\n",
      "[INFO 2018-06-27 15:27:39,146 cleverhans] Epoch 9 took 0.006289243698120117 seconds\n",
      "[INFO 2018-06-27 15:27:39,147 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-06-27 15:28:29,212 cleverhans] Epoch 0 took 0.05324435234069824 seconds\n",
      "[INFO 2018-06-27 15:28:29,229 cleverhans] Epoch 1 took 0.01582956314086914 seconds\n",
      "[INFO 2018-06-27 15:28:29,242 cleverhans] Epoch 2 took 0.012974262237548828 seconds\n",
      "[INFO 2018-06-27 15:28:29,255 cleverhans] Epoch 3 took 0.01189565658569336 seconds\n",
      "[INFO 2018-06-27 15:28:29,268 cleverhans] Epoch 4 took 0.01256704330444336 seconds\n",
      "[INFO 2018-06-27 15:28:29,281 cleverhans] Epoch 5 took 0.012900590896606445 seconds\n",
      "[INFO 2018-06-27 15:28:29,294 cleverhans] Epoch 6 took 0.01212930679321289 seconds\n",
      "[INFO 2018-06-27 15:28:29,307 cleverhans] Epoch 7 took 0.012828826904296875 seconds\n",
      "[INFO 2018-06-27 15:28:29,320 cleverhans] Epoch 8 took 0.01245260238647461 seconds\n",
      "[INFO 2018-06-27 15:28:29,333 cleverhans] Epoch 9 took 0.012103080749511719 seconds\n",
      "[INFO 2018-06-27 15:28:29,334 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-06-27 15:30:31,186 cleverhans] Epoch 0 took 0.06531476974487305 seconds\n",
      "[INFO 2018-06-27 15:30:31,217 cleverhans] Epoch 1 took 0.030187368392944336 seconds\n",
      "[INFO 2018-06-27 15:30:31,248 cleverhans] Epoch 2 took 0.03095865249633789 seconds\n",
      "[INFO 2018-06-27 15:30:31,276 cleverhans] Epoch 3 took 0.027013778686523438 seconds\n",
      "[INFO 2018-06-27 15:30:31,308 cleverhans] Epoch 4 took 0.03169703483581543 seconds\n",
      "[INFO 2018-06-27 15:30:31,339 cleverhans] Epoch 5 took 0.03027820587158203 seconds\n",
      "[INFO 2018-06-27 15:30:31,368 cleverhans] Epoch 6 took 0.027655839920043945 seconds\n",
      "[INFO 2018-06-27 15:30:31,403 cleverhans] Epoch 7 took 0.03511214256286621 seconds\n",
      "[INFO 2018-06-27 15:30:31,437 cleverhans] Epoch 8 took 0.032843589782714844 seconds\n",
      "[INFO 2018-06-27 15:30:31,466 cleverhans] Epoch 9 took 0.028529882431030273 seconds\n",
      "[INFO 2018-06-27 15:30:31,467 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n"
     ]
    }
   ],
   "source": [
    "# Seed random number generator so tutorial is reproducible\n",
    "rng = numpy.random.RandomState([2017, 8, 30])\n",
    "\n",
    "# Thibault: Tensorflow stuff\n",
    "set_log_level(logging.DEBUG)\n",
    "assert setup_tutorial()\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "\n",
    "# Data\n",
    "X, Y = DATASETS_['german']()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30)\n",
    "X_sub = X_test[:holdout]\n",
    "Y_sub = numpy.argmax(Y_test[:holdout], axis=1)\n",
    "\n",
    "## Redefine test set as remaining samples unavailable to adversaries\n",
    "### N.B Thibault: c'est pour le substitute de Papernot\n",
    "X_test = X_test[holdout:]\n",
    "Y_test = Y_test[holdout:]\n",
    "print(\"Training black box on\",X_train.shape[0], \"examples\")\n",
    "print('Testing black box and substitute on', X_test.shape[0],' examples')\n",
    "print(\"Using \", holdout, \" examples to start PP substitute\")\n",
    "## Define input and output TF placeholders\n",
    "### N.B. Thibault: restes de Tensorflow, utilisé pour le substitute de Papernot...\n",
    "x = tf.placeholder(tf.float32, shape=(None, X.shape[1]))\n",
    "y = tf.placeholder(tf.float32, shape=(None, Y.shape[1]))  \n",
    "\n",
    "# Simulate the black-box model\n",
    "print(\"Preparing the black-box model.\")\n",
    "prep_bbox_out = BB_MODELS_['rf'](X_train, Y_train, X_test, Y_test)\n",
    "bb_model, bbox_preds, _ = prep_bbox_out #bbox_preds fonction predict\n",
    "\n",
    "# Train PAPERNOT substitute\n",
    "print(\"Training the Pépèrenot substitute model.\")\n",
    "train_sub_pap = train_sub(sess, x, y, bb_model, X_sub, Y_sub,\n",
    "                          nb_classes, nb_epochs_s, batch_size,\n",
    "                          learning_rate, data_aug, lmbda, rng=rng)\n",
    "model_sub, preds_sub = train_sub_pap\n",
    "\n",
    "eval_params = {'batch_size': batch_size}\n",
    "pap_acc = model_eval(sess, x, y, preds_sub, X_test, Y_test, args=eval_params) \n",
    "print(pap_acc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Local Surrogate substitute model.\n",
      "Calculating distances.\n",
      "Training Local Surrogate substitute model.\n",
      "Calculating distances.\n",
      "Training Local Surrogate substitute model.\n",
      "Calculating distances.\n",
      "Training Local Surrogate substitute model.\n",
      "Calculating distances.\n",
      "Training Local Surrogate substitute model.\n",
      "Calculating distances.\n",
      "Training Local Surrogate substitute model.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ee2e6700f176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sub_ls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLocalSurrogate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblackbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_support_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_surrogate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_toexplain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculating distances.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/local-adverse-detection/lad/lad.py\u001b[0m in \u001b[0;36mget_local_surrogate\u001b[0;34m(self, x_toexplain)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0msegment_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_segment_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_toexplain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mtouchpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_points_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_segment_boundary_touchpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_toexplain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mtouchpoint_hypersphere_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_random_points_hypersphere_touchpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtouchpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/local-adverse-detection/lad/lad.py\u001b[0m in \u001b[0;36mget_segment_boundary_touchpoint\u001b[0;34m(self, x_toexplain, support_point, segment_points, linear_model)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m## Label each drawn points on the segment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0msegment_points_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m## Find the min of the information gain (or ~ measure to get the frontier frontier touchpoint)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/local-adverse-detection/lad/lad.py\u001b[0m in \u001b[0;36mpred\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m     '''\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblackbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    587\u001b[0m         Parallel(n_jobs=n_jobs, verbose=self.verbose, backend=\"threading\")(\n\u001b[1;32m    588\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulate_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m             for e in self.estimators_)\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mproba\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_terminate_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_terminate_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_terminate_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# terminate does a join()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_terminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wr, _finalizer_registry, sub_debug, getpid)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 sub_debug('finalizer calling %s with args %s and kwargs %s',\n\u001b[1;32m    185\u001b[0m                           self._callback, self._args, self._kwargs)\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weakref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_terminate_pool\u001b[0;34m(cls, taskqueue, inqueue, outqueue, pool, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'joining worker handler'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mworker_handler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             \u001b[0mworker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;31m# Terminate workers which haven't already finished.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "\n",
    "def pred(x):\n",
    "        return bb_model.predict(x)[:,1]\n",
    "\n",
    "xs_toexplain = [pandas.Series(xi) for xi in X_test[:1000,:]]\n",
    "radius_perc=[0.05,0.1,0.2,0.3,0.4,0.5]#,0.6,0.7,0.8,0.9,1] \n",
    "papernot = {}\n",
    "localsurr = {}\n",
    "papernot = dict([(r, []) for r in radius_perc])\n",
    "localsurrogate = dict([(r, []) for r in radius_perc])\n",
    "c = 0\n",
    "\n",
    "\n",
    "\n",
    "for x_toexplain in xs_toexplain:\n",
    "    c += 1\n",
    "    if c % 100 == 0:\n",
    "        print('iter', c)\n",
    "    \n",
    "    print(\"Training Local Surrogate substitute model.\")\n",
    "    \n",
    "    \n",
    "    _, train_sub_ls = lad.LocalSurrogate(pandas.DataFrame(X), blackbox=bb_model, n_support_points=100, max_depth=3).get_local_surrogate(x_toexplain)\n",
    "    \n",
    "    print(\"Calculating distances.\")\n",
    "    dists = euclidean_distances(x_toexplain.to_frame().T, X)\n",
    "    #dists = pandas.Series(dists[0], index=X.index)\n",
    "    radius_all_ = dists.max()*numpy.array(radius_perc)\n",
    "\n",
    "    \n",
    "    for i in range(len(radius_all_)):\n",
    "        radius = radius_all_[i]\n",
    "        #support_x_ = numpy.array(get_random_points_hypersphere(x_toexplain, radius_=radius, n_points_=1000))\n",
    "        support_x_ = generate_inside_ball(numpy.array(x_toexplain), segment=(0, radius), n=1000)\n",
    "        \n",
    "\n",
    "        pap_fid = model_eval(sess, x, y, preds_sub, support_x_, bb_model.predict(support_x_) , args=eval_params)\n",
    "        papernot[radius_perc[i]].append(pap_fid)\n",
    "\n",
    "        ls_fid = accuracy_score(train_sub_ls.predict(support_x_), pred(support_x_))\n",
    "        localsurrogate[radius_perc[i]].append(ls_fid)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(lad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f092364a5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_localsurr = pandas.DataFrame(localsurrogate)\n",
    "out_papernot = pandas.DataFrame(papernot)\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.pointplot(data=out_papernot)\n",
    "sns.pointplot(data=out_localsurr, color='orange')\n",
    "plt.xlabel('Radius percent')\n",
    "plt.ylabel('Local Accuracy')\n",
    "plt.savefig('figures/local_fidelity_german.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_papernot.to_csv('aze.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "def sq(x):\n",
    "    return sq[0] + sq[1] / sq[0] + sq[1]\n",
    "\n",
    "with Pool(5) as p:\n",
    "    print(p.map(sq, [xs_toexplain]))\n",
    "    \n",
    "sum(xs_toexplain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
