{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\"\"\"\n",
    "This tutorial shows how to generate adversarial examples\n",
    "using FGSM in black-box setting.\n",
    "The original paper can be found at:\n",
    "https://arxiv.org/abs/1602.02697\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import flags\n",
    "\n",
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils import to_categorical\n",
    "from cleverhans.utils import set_log_level\n",
    "from cleverhans.utils_tf import model_train, model_eval, batch_eval\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.attacks_tf import jacobian_graph, jacobian_augmentation\n",
    "\n",
    "from cleverhans_tutorials.tutorial_models import make_basic_cnn, MLP\n",
    "from cleverhans_tutorials.tutorial_models import Flatten, Linear, ReLU, Softmax\n",
    "from cleverhans.utils import TemporaryLogLevel\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MOONS\n",
    "'''\n",
    "def get_moon():\n",
    "    X, y = make_moons(noise=0.3, random_state=1, n_samples=10000)\n",
    "    y2 = np.zeros((X.shape[0],2))\n",
    "    for k in range(len(y)):\n",
    "        y2[k][y[k]] = 1\n",
    "    return X, y2\n",
    "DATASETS_ = {'moons':get_moon}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a black-box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PAPERNOT BB\n",
    "'''\n",
    "def Papernot_bbox(sess, x, y, X_train, Y_train, X_test, Y_test,\n",
    "              nb_epochs, batch_size, learning_rate,\n",
    "              rng):\n",
    "    \"\"\"\n",
    "    Define and train a model that simulates the \"remote\"\n",
    "    black-box oracle described in the original paper.\n",
    "    :param sess: the TF session\n",
    "    :param x: the input placeholder for MNIST\n",
    "    :param y: the ouput placeholder for MNIST\n",
    "    :param X_train: the training data for the oracle\n",
    "    :param Y_train: the training labels for the oracle\n",
    "    :param X_test: the testing data for the oracle\n",
    "    :param Y_test: the testing labels for the oracle\n",
    "    :param nb_epochs: number of epochs to train model\n",
    "    :param batch_size: size of training batches\n",
    "    :param learning_rate: learning rate for training\n",
    "    :param rng: numpy.random.RandomState\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Define TF model graph (for the black-box model)\n",
    "    model = make_basic_cnn()\n",
    "    predictions = model(x)\n",
    "    print(\"Defined TensorFlow model graph.\")\n",
    "\n",
    "    # Train an MNIST model\n",
    "    train_params = {\n",
    "        'nb_epochs': nb_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate\n",
    "    }\n",
    "    model_train(sess, x, y, predictions, X_train, Y_train,\n",
    "                args=train_params, rng=rng)\n",
    "\n",
    "    # Print out the accuracy on legitimate data\n",
    "    eval_params = {'batch_size': batch_size}\n",
    "    accuracy = model_eval(sess, x, y, predictions, X_test, Y_test,\n",
    "                          args=eval_params)\n",
    "    print('Test accuracy of black-box on legitimate test '\n",
    "          'examples: ' + str(accuracy))\n",
    "\n",
    "    return model, predictions, accuracy\n",
    "\n",
    "def RF_bbox(X_train, Y_train, X_test, Y_test):\n",
    "    # Define RF model graph (for the black-box model)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, n_jobs=-1).fit(X_train, Y_train)\n",
    "    \n",
    "    # Print out the accuracy on legitimate data\n",
    "    predictions = model.predict_proba(X_test)[1]\n",
    "    \n",
    "    accuracy = accuracy_score(Y_test, model.predict(X_test))\n",
    "    #roc_auc = roc_auc_score(Y_test, predictions[1][:,1])\n",
    "    print('Test accuracy of black-box on legitimate test '\n",
    "          'examples: ' + str(accuracy))\n",
    "    #print('Test ROC AUC of black-box on legitimate test ' 'examples: ' + str(roc_auc))\n",
    "    return model, predictions, accuracy\n",
    "    \n",
    "BB_MODELS_ = {'dnn': PAP_bbox,\n",
    "            'rf': RF_bbox}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papernot Surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_tutorial():\n",
    "    \"\"\"\n",
    "    Helper function to check correct configuration of tf for tutorial\n",
    "    :return: True if setup checks completed\n",
    "    \"\"\"\n",
    "\n",
    "    # Set TF random seed to improve reproducibility\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    return True\n",
    "def substitute_model(img_rows=1, img_cols=2, nb_classes=2):\n",
    "    \"\"\"\n",
    "    Defines the model architecture to be used by the substitute. Use\n",
    "    the example model interface.\n",
    "    :param img_rows: number of rows in input\n",
    "    :param img_cols: number of columns in input\n",
    "    :param nb_classes: number of classes in output\n",
    "    :return: tensorflow model\n",
    "    \"\"\"\n",
    "    input_shape = (None, img_rows, img_cols, 1)\n",
    "\n",
    "    # Define a fully connected model (it's different than the black-box)\n",
    "    layers = [Flatten(),\n",
    "              Linear(200),\n",
    "              ReLU(),\n",
    "              Linear(200),\n",
    "              ReLU(),\n",
    "              Linear(nb_classes),\n",
    "              Softmax()]\n",
    "    layers = [Flatten(), Linear(nb_classes), Softmax()]\n",
    "\n",
    "    return MLP(layers, input_shape)\n",
    "\n",
    "\n",
    "def train_sub(sess, x, y, bbox_preds, X_sub, Y_sub, nb_classes,\n",
    "              nb_epochs_s, batch_size, learning_rate, data_aug, lmbda,\n",
    "              rng):\n",
    "    \"\"\"\n",
    "    This function creates the substitute by alternatively\n",
    "    augmenting the training data and training the substitute.\n",
    "    :param sess: TF session\n",
    "    :param x: input TF placeholder\n",
    "    :param y: output TF placeholder\n",
    "    :param bbox_preds: output of black-box model predictions\n",
    "    :param X_sub: initial substitute training data\n",
    "    :param Y_sub: initial substitute training labels\n",
    "    :param nb_classes: number of output classes\n",
    "    :param nb_epochs_s: number of epochs to train substitute model\n",
    "    :param batch_size: size of training batches\n",
    "    :param learning_rate: learning rate for training\n",
    "    :param data_aug: number of times substitute training data is augmented\n",
    "    :param lmbda: lambda from arxiv.org/abs/1602.02697\n",
    "    :param rng: numpy.random.RandomState instance\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Define TF model graph (for the black-box model)\n",
    "    model_sub = substitute_model()\n",
    "    preds_sub = model_sub(x)\n",
    "    print(\"Defined TensorFlow model graph for the substitute.\")\n",
    "\n",
    "    # Define the Jacobian symbolically using TensorFlow\n",
    "    grads = jacobian_graph(preds_sub, x, nb_classes)\n",
    "\n",
    "    # Train the substitute and augment dataset alternatively\n",
    "    for rho in xrange(data_aug):\n",
    "        print(\"Substitute training epoch #\" + str(rho))\n",
    "        train_params = {\n",
    "            'nb_epochs': nb_epochs_s,\n",
    "            'batch_size': batch_size,\n",
    "            'learning_rate': learning_rate\n",
    "        }\n",
    "        with TemporaryLogLevel(logging.WARNING, \"cleverhans.utils.tf\"):\n",
    "            model_train(sess, x, y, preds_sub, X_sub,\n",
    "                        to_categorical(Y_sub, nb_classes),\n",
    "                        init_all=False, args=train_params, rng=rng)\n",
    "\n",
    "        # If we are not at last substitute training iteration, augment dataset\n",
    "        if rho < data_aug - 1:\n",
    "            print(\"Augmenting substitute training data.\")\n",
    "            # Perform the Jacobian augmentation\n",
    "            lmbda_coef = 2 * int(int(rho / 3) != 0) - 1\n",
    "            X_sub = jacobian_augmentation(sess, x, X_sub, Y_sub, grads,\n",
    "                                          lmbda_coef * lmbda)\n",
    "\n",
    "            print(\"Labeling substitute training data.\")\n",
    "            # Label the newly generated synthetic points using the black-box\n",
    "            Y_sub = np.hstack([Y_sub, Y_sub])\n",
    "            X_sub_prev = X_sub[int(len(X_sub)/2):]\n",
    "            eval_params = {'batch_size': 200}#ok je donnerai \n",
    "            \n",
    "            bbox_preds = tf.convert_to_tensor(bbox_preds, dtype=tf.float32)            \n",
    "            print('x sub prev', X_sub_prev.shape)\n",
    "            bbox_val = batch_eval2(sess, [x], [bbox_preds], [X_sub_prev], args=eval_params)[0]\n",
    "            \n",
    "            # Note here that we take the argmax because the adversary\n",
    "            # only has access to the label (not the probabilities) output\n",
    "            # by the black-box model\n",
    "            Y_sub[int(len(X_sub)/2):] = np.argmax(bbox_val, axis=1)\n",
    "\n",
    "    return model_sub, preds_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the black-box model.\n",
      "Test accuracy of black-box on legitimate test examples: 0.8955\n",
      "Training the substitute model.\n",
      "Defined TensorFlow model graph for the substitute.\n",
      "Substitute training epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-06-21 16:45:37,295 cleverhans] Epoch 0 took 0.12337374687194824 seconds\n",
      "INFO:cleverhans:Epoch 0 took 0.12337374687194824 seconds\n",
      "[INFO 2018-06-21 16:45:37,296 cleverhans] Completed model training.\n",
      "INFO:cleverhans:Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "x sub prev (10, 2)\n",
      "start 0\n",
      "end 200\n",
      "input batches [array([[ 0.60280051,  0.76102675],\n",
      "       [-0.85730031, -0.01678787],\n",
      "       [-1.23908612,  0.50445917],\n",
      "       [-0.4489277 ,  0.75046783],\n",
      "       [ 1.25778821, -0.00768521],\n",
      "       [ 0.88444481,  0.18134661],\n",
      "       [ 0.33922971, -0.07833283],\n",
      "       [ 0.10649866,  0.91411409],\n",
      "       [-0.6601705 ,  0.16874348],\n",
      "       [ 0.96139662,  0.56414275]])]\n",
      "feed_dict {<tf.Tensor 'Placeholder_168:0' shape=(?, 2) dtype=float32>: array([[ 0.60280051,  0.76102675],\n",
      "       [-0.85730031, -0.01678787],\n",
      "       [-1.23908612,  0.50445917],\n",
      "       [-0.4489277 ,  0.75046783],\n",
      "       [ 1.25778821, -0.00768521],\n",
      "       [ 0.88444481,  0.18134661],\n",
      "       [ 0.33922971, -0.07833283],\n",
      "       [ 0.10649866,  0.91411409],\n",
      "       [-0.6601705 ,  0.16874348],\n",
      "       [ 0.96139662,  0.56414275]])}\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " ..., \n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n",
      "(2000, 2)\n",
      "10\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "(2000, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-fe71c66caf9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_fidelity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-116-005169cf7a08>\u001b[0m in \u001b[0;36mmain_fidelity\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     train_sub_out = train_sub(sess, x, y, bbox_preds, X_sub, Y_sub,\n\u001b[1;32m     36\u001b[0m                               \u001b[0mnb_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                               learning_rate, data_aug, lmbda, rng=rng)\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mmodel_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_sub_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-186-e541e7278b95>\u001b[0m in \u001b[0;36mtrain_sub\u001b[0;34m(sess, x, y, bbox_preds, X_sub, Y_sub, nb_classes, nb_epochs_s, batch_size, learning_rate, data_aug, lmbda, rng)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mbbox_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x sub prev'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_sub_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mbbox_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_eval2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbbox_preds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX_sub_prev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Note here that we take the argmax because the adversary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-184-a512211e7e2b>\u001b[0m in \u001b[0;36mbatch_eval2\u001b[0;34m(sess, tf_inputs, tf_outputs, numpy_inputs, feed, args)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcur_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mout_elem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_output_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_output_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mout_elem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_output_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: (2000, 2)"
     ]
    }
   ],
   "source": [
    "main_fidelity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_eval2(sess, tf_inputs, tf_outputs, numpy_inputs, feed=None,\n",
    "               args=None):\n",
    "    \"\"\"\n",
    "    A helper function that computes a tensor on numpy inputs by batches.\n",
    "    :param sess:\n",
    "    :param tf_inputs:\n",
    "    :param tf_outputs:\n",
    "    :param numpy_inputs:\n",
    "    :param feed: An optional dictionary that is appended to the feeding\n",
    "             dictionary before the session runs. Can be used to feed\n",
    "             the learning phase of a Keras model for instance.\n",
    "    :param args: dict or argparse `Namespace` object.\n",
    "                 Should contain `batch_size`\n",
    "    \"\"\"\n",
    "    args = _ArgsWrapper(args or {})\n",
    "\n",
    "    assert args.batch_size, \"Batch size was not given in args dict\"\n",
    "\n",
    "    n = len(numpy_inputs)\n",
    "    assert n > 0\n",
    "    assert n == len(tf_inputs)\n",
    "    m = numpy_inputs[0].shape[0]\n",
    "    for i in xrange(1, n):\n",
    "        assert numpy_inputs[i].shape[0] == m\n",
    "    out = []\n",
    "    for _ in tf_outputs:\n",
    "        out.append([])\n",
    "    with sess.as_default():\n",
    "        for start in xrange(0, m, args.batch_size):\n",
    "            batch = start // args.batch_size\n",
    "            if batch % 100 == 0 and batch > 0:\n",
    "                _logger.debug(\"Batch \" + str(batch))\n",
    "\n",
    "            # Compute batch start and end indices\n",
    "            start = batch * args.batch_size\n",
    "            end = start + args.batch_size\n",
    "            print('start', start)\n",
    "            print('end', end)\n",
    "            numpy_input_batches = [numpy_input[start:end]\n",
    "                                   for numpy_input in numpy_inputs]\n",
    "            print('input batches', numpy_input_batches.shape)\n",
    "            cur_batch_size = numpy_input_batches[0].shape[0]\n",
    "            assert cur_batch_size <= args.batch_size\n",
    "            \n",
    "            for e in numpy_input_batches:\n",
    "                assert e.shape[0] == cur_batch_size\n",
    "\n",
    "            feed_dict = dict(zip(tf_inputs, numpy_input_batches))\n",
    "            print('feed_dict', feed_dict)\n",
    "            if feed is not None:\n",
    "                feed_dict.update(feed)\n",
    "            numpy_output_batches = sess.run(tf_outputs, feed_dict=feed_dict) #PROBLEME ICI : AU LIEU DES BATCHES, TOUT LE DATASET DE PRED\n",
    "            for e in numpy_output_batches:\n",
    "                print(e)\n",
    "                print(e.shape)\n",
    "                print(cur_batch_size)\n",
    "                assert e.shape[0] == cur_batch_size, e.shape #ERREUR ICI\n",
    "            for out_elem, numpy_output_batch in zip(out, numpy_output_batches):\n",
    "                out_elem.append(numpy_output_batch)\n",
    "\n",
    "    out = [np.concatenate(x, axis=0) for x in out]\n",
    "    for e in out:\n",
    "        assert e.shape[0] == m, e.shape\n",
    "    return out\n",
    "\n",
    "class _ArgsWrapper(object):\n",
    "\n",
    "    \"\"\"\n",
    "    Wrapper that allows attribute access to dictionaries\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args):\n",
    "        if not isinstance(args, dict):\n",
    "            args = vars(args)\n",
    "        self.args = args\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return self.args.get(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage: \n",
    "print(\"Training the substitute model.\")\n",
    "    train_sub_out = train_sub(sess, x, y, bbox_preds, X_sub, Y_sub,\n",
    "                              nb_classes, nb_epochs_s, batch_size,\n",
    "                              learning_rate, data_aug, lmbda, rng=rng)\n",
    "    model_sub, preds_sub = train_sub_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-b5fec669aca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model_eval(sess, x, y, preds_sub, X_test, Y_test, args=eval_params)1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the black-box model.\n",
      "Test accuracy of black-box on legitimate test examples: 0.88\n",
      "Training the substitute model.\n",
      "Defined TensorFlow model graph for the substitute.\n",
      "Substitute training epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-06-21 15:25:24,045 cleverhans] Epoch 0 took 0.06192493438720703 seconds\n",
      "INFO:cleverhans:Epoch 0 took 0.06192493438720703 seconds\n",
      "[INFO 2018-06-21 15:25:24,046 cleverhans] Completed model training.\n",
      "INFO:cleverhans:Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument array([[ 0.  ,  1.  ],\n       [ 0.  ,  1.  ],\n       [ 0.48,  0.52],\n       [ 1.  ,  0.  ],\n       [ 0.14,  0.86],\n       [ 0.05,  0.95],\n       [ 0.95,  0.05],\n       [ 1.  ,  0.  ],\n       [ 0.69,  0.31],\n       [ 0.  ,  1.  ],\n       [ 0.53,  0.47],\n       [ 0.03,  0.97],\n       [ 0.96,  0.04],\n       [ 0.89,  0.11],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 1.  ,  0.  ],\n       [ 0.  ,  1.  ],\n       [ 0.16,  0.84],\n       [ 0.  ,  1.  ],\n       [ 0.11,  0.89],\n       [ 1.  ,  0.  ],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 0.17,  0.83],\n       [ 0.19,  0.81],\n       [ 0.  ,  1.  ],\n       [ 0.01,  0.99],\n       [ 0.11,  0.89],\n       [ 1.  ,  0.  ],\n       [ 1.  ,  0.  ],\n       [ 0.01,  0.99],\n       [ 0.64,  0.36],\n       [ 0.5 ,  0.5 ],\n       [ 0.  ,  1.  ],\n       [ 0.69,  0.31],\n       [ 0.29,  0.71],\n       [ 1.  ,  0.  ],\n       [ 0.02,  0.98],\n       [ 0.99,  0.01],\n       [ 1.  ,  0.  ],\n       [ 0.56,  0.44],\n       [ 0.  ,  1.  ],\n       [ 0.06,  0.94],\n       [ 0.01,  0.99],\n       [ 0.  ,  1.  ],\n       [ 0.03,  0.97],\n       [ 0.97,  0.03],\n       [ 0.07,  0.93],\n       [ 0.03,  0.97],\n       [ 1.  ,  0.  ],\n       [ 0.8 ,  0.2 ],\n       [ 0.67,  0.33],\n       [ 0.99,  0.01],\n       [ 0.05,  0.95],\n       [ 1.  ,  0.  ],\n       [ 0.  ,  1.  ],\n       [ 0.99,  0.01],\n       [ 0.11,  0.89],\n       [ 0.12,  0.88],\n       [ 0.01,  0.99],\n       [ 0.97,  0.03],\n       [ 1.  ,  0.  ],\n       [ 0.02,  0.98],\n       [ 1.  ,  0.  ],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 0.06,  0.94],\n       [ 0.38,  0.62],\n       [ 1.  ,  0.  ],\n       [ 0.  ,  1.  ],\n       [ 0.92,  0.08],\n       [ 0.21,  0.79],\n       [ 1.  ,  0.  ],\n       [ 0.98,  0.02],\n       [ 0.93,  0.07],\n       [ 0.88,  0.12],\n       [ 0.03,  0.97],\n       [ 0.99,  0.01],\n       [ 0.  ,  1.  ],\n       [ 0.47,  0.53],\n       [ 1.  ,  0.  ],\n       [ 0.09,  0.91],\n       [ 1.  ,  0.  ],\n       [ 0.3 ,  0.7 ],\n       [ 0.97,  0.03],\n       [ 0.71,  0.29],\n       [ 0.99,  0.01],\n       [ 0.58,  0.42],\n       [ 0.87,  0.13],\n       [ 0.03,  0.97],\n       [ 0.94,  0.06],\n       [ 0.14,  0.86],\n       [ 0.75,  0.25],\n       [ 0.  ,  1.  ],\n       [ 0.19,  0.81],\n       [ 0.06,  0.94],\n       [ 1.  ,  0.  ],\n       [ 0.74,  0.26],\n       [ 1.  ,  0.  ],\n       [ 0.97,  0.03],\n       [ 0.99,  0.01],\n       [ 0.99,  0.01],\n       [ 0.97,  0.03],\n       [ 0.02,  0.98],\n       [ 0.01,  0.99],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 0.99,  0.01],\n       [ 0.  ,  1.  ],\n       [ 0.  ,  1.  ],\n       [ 0.11,  0.89],\n       [ 0.15,  0.85],\n       [ 0.14,  0.86],\n       [ 0.99,  0.01],\n       [ 0.66,  0.34],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 0.75,  0.25],\n       [ 0.  ,  1.  ],\n       [ 0.32,  0.68],\n       [ 0.02,  0.98],\n       [ 0.01,  0.99],\n       [ 0.  ,  1.  ],\n       [ 0.85,  0.15],\n       [ 0.  ,  1.  ],\n       [ 0.01,  0.99],\n       [ 1.  ,  0.  ],\n       [ 0.01,  0.99],\n       [ 0.01,  0.99],\n       [ 0.93,  0.07],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 0.44,  0.56],\n       [ 0.98,  0.02],\n       [ 0.01,  0.99],\n       [ 0.17,  0.83],\n       [ 0.08,  0.92],\n       [ 0.02,  0.98],\n       [ 1.  ,  0.  ],\n       [ 0.99,  0.01],\n       [ 0.95,  0.05],\n       [ 0.21,  0.79],\n       [ 0.96,  0.04],\n       [ 0.  ,  1.  ],\n       [ 0.  ,  1.  ],\n       [ 0.74,  0.26],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 0.  ,  1.  ],\n       [ 0.85,  0.15],\n       [ 0.  ,  1.  ],\n       [ 0.98,  0.02],\n       [ 0.  ,  1.  ],\n       [ 0.32,  0.68],\n       [ 1.  ,  0.  ],\n       [ 1.  ,  0.  ],\n       [ 0.2 ,  0.8 ],\n       [ 0.01,  0.99],\n       [ 0.91,  0.09],\n       [ 0.07,  0.93],\n       [ 0.  ,  1.  ],\n       [ 0.5 ,  0.5 ],\n       [ 0.  ,  1.  ],\n       [ 0.43,  0.57],\n       [ 0.03,  0.97],\n       [ 0.7 ,  0.3 ],\n       [ 0.  ,  1.  ],\n       [ 0.2 ,  0.8 ],\n       [ 0.99,  0.01],\n       [ 0.  ,  1.  ],\n       [ 0.64,  0.36],\n       [ 0.12,  0.88],\n       [ 0.53,  0.47],\n       [ 0.93,  0.07],\n       [ 0.  ,  1.  ],\n       [ 0.09,  0.91],\n       [ 0.9 ,  0.1 ],\n       [ 0.03,  0.97],\n       [ 0.97,  0.03],\n       [ 0.63,  0.37],\n       [ 0.02,  0.98],\n       [ 0.33,  0.67],\n       [ 0.3 ,  0.7 ],\n       [ 0.  ,  1.  ],\n       [ 0.9 ,  0.1 ],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 0.94,  0.06],\n       [ 0.95,  0.05],\n       [ 1.  ,  0.  ],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 0.04,  0.96],\n       [ 0.87,  0.13],\n       [ 1.  ,  0.  ],\n       [ 1.  ,  0.  ],\n       [ 0.03,  0.97],\n       [ 0.1 ,  0.9 ],\n       [ 0.83,  0.17]]) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    281\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 282\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    283\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3589\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3678\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" % (type(obj).__name__,\n\u001b[0;32m-> 3679\u001b[0;31m                                                            types_str))\n\u001b[0m\u001b[1;32m   3680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can not convert a ndarray into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-005169cf7a08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.01\u001b[0m \u001b[0;31m#FLAGS.lmbda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mmain_fidelity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-116-005169cf7a08>\u001b[0m in \u001b[0;36mmain_fidelity\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     train_sub_out = train_sub(sess, x, y, bbox_preds, X_sub, Y_sub,\n\u001b[1;32m     36\u001b[0m                               \u001b[0mnb_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                               learning_rate, data_aug, lmbda, rng=rng)\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mmodel_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_sub_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-d09c9f256e83>\u001b[0m in \u001b[0;36mtrain_sub\u001b[0;34m(sess, x, y, bbox_preds, X_sub, Y_sub, nb_classes, nb_epochs_s, batch_size, learning_rate, data_aug, lmbda, rng)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             bbox_val = batch_eval(sess, [x], [bbox_preds], [X_sub_prev],\n\u001b[0;32m---> 92\u001b[0;31m                                   args=eval_params)[0]\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0;31m# Note here that we take the argmax because the adversary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;31m# only has access to the label (not the probabilities) output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/src/cleverhans/cleverhans/utils_tf.py\u001b[0m in \u001b[0;36mbatch_eval\u001b[0;34m(sess, tf_inputs, tf_outputs, numpy_inputs, feed, args)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfeed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mnumpy_output_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumpy_output_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcur_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1120\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \"\"\"\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \"\"\"\n\u001b[1;32m    351\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \"\"\"\n\u001b[1;32m    351\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \"\"\"\n\u001b[1;32m    351\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \"\"\"\n\u001b[1;32m    351\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[0;32m~/Documents/thesis/code/new_envp36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    284\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[1;32m    285\u001b[0m                         \u001b[0;34m'must be a string or Tensor. (%s)'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                         (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[1;32m    287\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument array([[ 0.  ,  1.  ],\n       [ 0.  ,  1.  ],\n       [ 0.48,  0.52],\n       [ 1.  ,  0.  ],\n       [ 0.14,  0.86],\n       [ 0.05,  0.95],\n       [ 0.95,  0.05],\n       [ 1.  ,  0.  ],\n       [ 0.69,  0.31],\n       [ 0.  ,  1.  ],\n       [ 0.53,  0.47],\n       [ 0.03,  0.97],\n       [ 0.96,  0.04],\n       [ 0.89,  0.11],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 1.  ,  0.  ],\n       [ 0.  ,  1.  ],\n       [ 0.16,  0.84],\n       [ 0.  ,  1.  ],\n       [ 0.11,  0.89],\n       [ 1.  ,  0.  ],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 0.17,  0.83],\n       [ 0.19,  0.81],\n       [ 0.  ,  1.  ],\n       [ 0.01,  0.99],\n       [ 0.11,  0.89],\n       [ 1.  ,  0.  ],\n       [ 1.  ,  0.  ],\n       [ 0.01,  0.99],\n       [ 0.64,  0.36],\n       [ 0.5 ,  0.5 ],\n       [ 0.  ,  1.  ],\n       [ 0.69,  0.31],\n       [ 0.29,  0.71],\n       [ 1.  ,  0.  ],\n       [ 0.02,  0.98],\n       [ 0.99,  0.01],\n       [ 1.  ,  0.  ],\n       [ 0.56,  0.44],\n       [ 0.  ,  1.  ],\n       [ 0.06,  0.94],\n       [ 0.01,  0.99],\n       [ 0.  ,  1.  ],\n       [ 0.03,  0.97],\n       [ 0.97,  0.03],\n       [ 0.07,  0.93],\n       [ 0.03,  0.97],\n       [ 1.  ,  0.  ],\n       [ 0.8 ,  0.2 ],\n       [ 0.67,  0.33],\n       [ 0.99,  0.01],\n       [ 0.05,  0.95],\n       [ 1.  ,  0.  ],\n       [ 0.  ,  1.  ],\n       [ 0.99,  0.01],\n       [ 0.11,  0.89],\n       [ 0.12,  0.88],\n       [ 0.01,  0.99],\n       [ 0.97,  0.03],\n       [ 1.  ,  0.  ],\n       [ 0.02,  0.98],\n       [ 1.  ,  0.  ],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 0.06,  0.94],\n       [ 0.38,  0.62],\n       [ 1.  ,  0.  ],\n       [ 0.  ,  1.  ],\n       [ 0.92,  0.08],\n       [ 0.21,  0.79],\n       [ 1.  ,  0.  ],\n       [ 0.98,  0.02],\n       [ 0.93,  0.07],\n       [ 0.88,  0.12],\n       [ 0.03,  0.97],\n       [ 0.99,  0.01],\n       [ 0.  ,  1.  ],\n       [ 0.47,  0.53],\n       [ 1.  ,  0.  ],\n       [ 0.09,  0.91],\n       [ 1.  ,  0.  ],\n       [ 0.3 ,  0.7 ],\n       [ 0.97,  0.03],\n       [ 0.71,  0.29],\n       [ 0.99,  0.01],\n       [ 0.58,  0.42],\n       [ 0.87,  0.13],\n       [ 0.03,  0.97],\n       [ 0.94,  0.06],\n       [ 0.14,  0.86],\n       [ 0.75,  0.25],\n       [ 0.  ,  1.  ],\n       [ 0.19,  0.81],\n       [ 0.06,  0.94],\n       [ 1.  ,  0.  ],\n       [ 0.74,  0.26],\n       [ 1.  ,  0.  ],\n       [ 0.97,  0.03],\n       [ 0.99,  0.01],\n       [ 0.99,  0.01],\n       [ 0.97,  0.03],\n       [ 0.02,  0.98],\n       [ 0.01,  0.99],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 0.99,  0.01],\n       [ 0.  ,  1.  ],\n       [ 0.  ,  1.  ],\n       [ 0.11,  0.89],\n       [ 0.15,  0.85],\n       [ 0.14,  0.86],\n       [ 0.99,  0.01],\n       [ 0.66,  0.34],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 0.75,  0.25],\n       [ 0.  ,  1.  ],\n       [ 0.32,  0.68],\n       [ 0.02,  0.98],\n       [ 0.01,  0.99],\n       [ 0.  ,  1.  ],\n       [ 0.85,  0.15],\n       [ 0.  ,  1.  ],\n       [ 0.01,  0.99],\n       [ 1.  ,  0.  ],\n       [ 0.01,  0.99],\n       [ 0.01,  0.99],\n       [ 0.93,  0.07],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 0.44,  0.56],\n       [ 0.98,  0.02],\n       [ 0.01,  0.99],\n       [ 0.17,  0.83],\n       [ 0.08,  0.92],\n       [ 0.02,  0.98],\n       [ 1.  ,  0.  ],\n       [ 0.99,  0.01],\n       [ 0.95,  0.05],\n       [ 0.21,  0.79],\n       [ 0.96,  0.04],\n       [ 0.  ,  1.  ],\n       [ 0.  ,  1.  ],\n       [ 0.74,  0.26],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 0.  ,  1.  ],\n       [ 0.85,  0.15],\n       [ 0.  ,  1.  ],\n       [ 0.98,  0.02],\n       [ 0.  ,  1.  ],\n       [ 0.32,  0.68],\n       [ 1.  ,  0.  ],\n       [ 1.  ,  0.  ],\n       [ 0.2 ,  0.8 ],\n       [ 0.01,  0.99],\n       [ 0.91,  0.09],\n       [ 0.07,  0.93],\n       [ 0.  ,  1.  ],\n       [ 0.5 ,  0.5 ],\n       [ 0.  ,  1.  ],\n       [ 0.43,  0.57],\n       [ 0.03,  0.97],\n       [ 0.7 ,  0.3 ],\n       [ 0.  ,  1.  ],\n       [ 0.2 ,  0.8 ],\n       [ 0.99,  0.01],\n       [ 0.  ,  1.  ],\n       [ 0.64,  0.36],\n       [ 0.12,  0.88],\n       [ 0.53,  0.47],\n       [ 0.93,  0.07],\n       [ 0.  ,  1.  ],\n       [ 0.09,  0.91],\n       [ 0.9 ,  0.1 ],\n       [ 0.03,  0.97],\n       [ 0.97,  0.03],\n       [ 0.63,  0.37],\n       [ 0.02,  0.98],\n       [ 0.33,  0.67],\n       [ 0.3 ,  0.7 ],\n       [ 0.  ,  1.  ],\n       [ 0.9 ,  0.1 ],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 0.94,  0.06],\n       [ 0.95,  0.05],\n       [ 1.  ,  0.  ],\n       [ 0.  ,  1.  ],\n       [ 1.  ,  0.  ],\n       [ 0.04,  0.96],\n       [ 0.87,  0.13],\n       [ 1.  ,  0.  ],\n       [ 1.  ,  0.  ],\n       [ 0.03,  0.97],\n       [ 0.1 ,  0.9 ],\n       [ 0.83,  0.17]]) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "\n",
    "def main_fidelity():\n",
    "    # Trucs que je comprends pas\n",
    "    set_log_level(logging.DEBUG)\n",
    "    assert setup_tutorial()\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    accuracies = {}\n",
    "    X, Y = DATASETS_['moons']()\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20)\n",
    "    X_sub = X_test[:holdout]\n",
    "    Y_sub = np.argmax(Y_test[:holdout], axis=1)\n",
    "    '''\n",
    "    Pour PAPERNOT + blackbox si DNN (jy connais évidemment rien à tensorflow)\n",
    "    '''\n",
    "    '''# Redefine test set as remaining samples unavailable to adversaries\n",
    "    X_test = X_test[holdout:]\n",
    "    Y_test = Y_test[holdout:]'''\n",
    "    # Define input and output TF placeholders\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "    \n",
    "    # Seed random number generator so tutorial is reproducible\n",
    "    rng = np.random.RandomState([2017, 8, 30])\n",
    "    \n",
    "    # Simulate the black-box model locally\n",
    "    # You could replace this by a remote labeling API for instance\n",
    "    print(\"Preparing the black-box model.\")\n",
    "    prep_bbox_out = BB_MODELS_['rf'](X_train, Y_train, X_test, Y_test) #(sess, x, y, X_train, Y_train, X_test, Y_test, nb_epochs, batch_size, learning_rate, rng) #ici marche pas mais de toute facon on veut pas le rendre generique on veut juste choisir un clf\n",
    "    model, bbox_preds, accuracies['bbox'] = prep_bbox_out\n",
    "\n",
    "    # Train PAPERNOT substitute\n",
    "    print(\"Training the substitute model.\")\n",
    "    train_sub_out = train_sub(sess, x, y, bbox_preds, X_sub, Y_sub,\n",
    "                              nb_classes, nb_epochs_s, batch_size,\n",
    "                              learning_rate, data_aug, lmbda, rng=rng)\n",
    "    model_sub, preds_sub = train_sub_out\n",
    "    \n",
    "    \n",
    "    # Train OUR subtitute\n",
    "    \n",
    "    \n",
    "    # Evaluate the Papernot substitute model on clean test examples\n",
    "    eval_params = {'batch_size': batch_size}\n",
    "    acc = model_eval(sess, x, y, preds_sub, X_test, Y_test, args=eval_params)\n",
    "    accuracies['sub'] = acc\n",
    "    return acc\n",
    "nb_classes=2 #\n",
    "batch_size=2 #FLAGS.batch_size\n",
    "learning_rate=0.001 #FLAGS.learning_rate\n",
    "nb_epochs=1 #FLAGS.nb_epochs, \n",
    "holdout=10 #FLAGS.holdout\n",
    "data_aug=3 #FLAGS.data_aug, \n",
    "nb_epochs_s=1 #FLAGS.nb_epochs_s,\n",
    "lmbda=.01 #FLAGS.lmbda\n",
    "\n",
    "main_fidelity()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
